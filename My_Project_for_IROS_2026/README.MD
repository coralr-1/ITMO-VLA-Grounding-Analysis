# ğŸ¤– AI-Powered Shadow Hand ASL Control System
# ğŸ¤– AIé©±åŠ¨çš„Shadow Handæ‰‹è¯­æ§åˆ¶ç³»ç»Ÿ

[English](#english) | [ä¸­æ–‡](#chinese)

---

<a name="english"></a>

## ğŸ“– English Version

### ğŸ¯ Project Overview

An intelligent robotic hand control system that **listens to your voice**, **corrects speech recognition errors**, **translates Chinese to English**, and controls a simulated Shadow Hand to perform American Sign Language (ASL) finger-spelling gestures.

**ğŸ¥ Demo Video**: [LLM_robots.mp4](../)

### âœ¨ Key Features

- ğŸ¤ **Voice Recognition**: Real-time Chinese speech input via Google Speech API
- ğŸ§  **AI Error Correction**: Local LLM automatically fixes homophones and typos (e.g., "æ€ä¹ˆå‘¨" â†’ "æ€ä¹ˆèµ°")
- ğŸŒ **Translation**: Chinese â†’ English translation with letter sequence generation
- ğŸ¤– **Closed-Loop Control**: Smooth motion with joint position feedback (no glitchy movements)
- ğŸ”¤ **Complete ASL Alphabet**: A-Z gesture support using Shadow Hand simulation
- ğŸ’» **PyBullet Physics**: Realistic robotic hand simulation with gravity and collision

---

### ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Voice     â”‚â”€â”€â”€â”€â”€â”€â”‚     LLM      â”‚â”€â”€â”€â”€â”€â”€â”‚   Shadow    â”‚
â”‚  (Chinese)  â”‚ ASR  â”‚  (Correct +  â”‚ JSON â”‚    Hand     â”‚
â”‚  Microphone â”‚      â”‚   Translate) â”‚      â”‚ (PyBullet)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                     â”‚ LM Studio   â”‚
                     â”‚ Local API   â”‚
                     â”‚ Port: 1234  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Workflow**:
1. User speaks in Chinese via microphone
2. Google Speech API transcribes to text (may contain errors)
3. Local LLM corrects errors & translates to English
4. System converts to letter sequence: `["H","E","L","L","O"]`
5. Shadow Hand executes ASL gestures sequentially

---

### ğŸ“‹ Prerequisites

| Requirement | Specification |
|------------|---------------|
| **OS** | Windows 10/11, Linux (Ubuntu 20.04+) |
| **Python** | 3.10 or higher |
| **LLM Server** | [LM Studio](https://lmstudio.ai/) (for local inference) |
| **Hardware** | Microphone (required), Internet connection (for Google ASR) |
| **GPU** | Optional (improves rendering quality) |

---

### ğŸš€ Installation

#### Step 1: Clone/Download Project

Ensure these files are in the **same directory**:
```
asl_robot_project/
â”œâ”€â”€ asl_main.py              # Main control script
â”œâ”€â”€ my_shadow_hand.urdf      # Shadow Hand robot model
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # This file
```

#### Step 2: Install Python Dependencies

**Windows:**
```bash
pip install -r requirements.txt

# If pyaudio fails, use:
pip install pipwin
pipwin install pyaudio
```

**Linux (Ubuntu):**
```bash
# Install system-level audio libraries
sudo apt-get update
sudo apt-get install python3-pyaudio portaudio19-dev

# Install Python packages
pip install -r requirements.txt
```

#### Step 3: Setup LM Studio (LLM Server)

1. Download and install [LM Studio](https://lmstudio.ai/)
2. Open LM Studio and download a model:
   - **Recommended**: `Qwen2.5-1.5B-Instruct` (fast) or `Qwen2.5-7B-Instruct` (more accurate)
3. Click **Local Server** (icon with bidirectional arrows) in the left sidebar
4. Click green **Start Server** button at the top
5. Verify the console shows: `Server running at http://localhost:1234`

---

### ğŸ® Usage

#### Starting the System

```bash
python asl_main.py
```

**Expected output:**
```
æ­£åœ¨å¯åŠ¨ PyBullet...
=== Shadow Hand æ™ºèƒ½æ§åˆ¶ç³»ç»Ÿ ===
æ“ä½œæŒ‡å—: æŒ‰ 'v' é”®è¯´è¯ï¼ŒæŒ‰ 'q' é€€å‡º

è¾“å…¥æŒ‡ä»¤ (v=è¯­éŸ³, q=é€€å‡º):
```

#### Operation Modes

**Mode A: Voice Control (Recommended âœ¨)**

1. Type `v` and press Enter
2. Wait for: `ğŸ¤ æ­£åœ¨è°ƒæ•´ç¯å¢ƒå™ªéŸ³...` (stay silent for 1 second)
3. When you see `ğŸ”´ è¯·è¯´è¯! (Listening...)`, speak in Chinese
   - Example: *"ä½ å¥½æˆ‘æƒ³å»å­¦æ ¡"* (Hello, I want to go to school)
4. The system will:
   - Recognize speech â†’ Correct errors â†’ Translate â†’ Execute ASL gestures

**Example Output:**
```
ğŸ‘‚ å¬åˆ°: ã€ ä½ å¥½æ€ä¹ˆå‘¨ ã€‘
ğŸ§  å‘é€ç»™å¤§è„‘çº é”™: ä½ å¥½æ€ä¹ˆå‘¨ ...
âœ¨ æ™ºèƒ½çº é”™: ä½ å¥½æ€ä¹ˆèµ°
ğŸ“– ç¿»è¯‘ç»“æœ: HELLO HOW TO GO
å‡†å¤‡æ‰§è¡Œåºåˆ—: ['H', 'E', 'L', 'L', 'O', ' ', 'H', 'O', 'W', ...]
>>> åŠ¨ä½œ: H
>>> åŠ¨ä½œ: E
...
```

**Mode B: Text Input (Debugging)**

1. Directly type Chinese or English text at the prompt
   - Example: `Hello World` or `ä½ å¥½`
2. Press Enter to execute gestures

**Exiting:**
- Type `q` and press Enter

---

### ğŸ§ª Demo Scenarios

Test the system's intelligence with challenging inputs:

#### Test 1: Homophone Correction
- **Input (voice)**: "æˆ‘æƒ³å»**ç¢è§‰**" (shuÃ¬ jiÃ o - intentional typo)
- **System Output**:
  ```
  âœ¨ æ™ºèƒ½çº é”™: æˆ‘æƒ³å»ç¡è§‰
  ğŸ“– ç¿»è¯‘: I WANT TO SLEEP
  ```
- **Action**: Spells `S-L-E-E-P`

#### Test 2: Long Sentence Translation
- **Input (voice)**: "æœºå™¨äººæŠ€æœ¯éå¸¸æœ‰è¶£"
- **System Output**:
  ```
  ğŸ“– ç¿»è¯‘: ROBOTICS IS VERY INTERESTING
  ```
- **Action**: Spells entire sentence

---

### ğŸ”§ Configuration

#### API Endpoint (Line 10 in `asl_main.py`)
```python
API_URL = "http://localhost:1234/v1/chat/completions"
```
- Default port is `1234` (LM Studio default)
- Change if using different LLM server

#### Graphics Mode (Line 33 in `asl_main.py`)
```python
# Current (compatibility mode):
p.connect(p.GUI, options="--opengl2")

# High-performance mode (requires good GPU):
p.connect(p.GUI)
```
- Remove `options="--opengl2"` for better graphics if you have NVIDIA GPU
- Revert if you experience crashes

---

### ğŸ› ï¸ Troubleshooting

| Problem | Solution |
|---------|----------|
| `ModuleNotFoundError: speech_recognition` | Run: `pip install SpeechRecognition` |
| Voice recognition timeout | 1. Check internet connection<br>2. Ensure microphone is not muted<br>3. Speak louder and slower |
| `Connection Error` to LLM | Verify LM Studio server is running on port 1234 |
| Hand moves too slowly | **Normal behavior** - closed-loop control ensures smooth motion |
| URDF loading error | Verify `my_shadow_hand.urdf` is in same directory as script |
| PyBullet crashes | Add `options="--opengl2"` to `p.connect()` line |

---

### ğŸ“‚ Project Structure

```
asl_robot_project/
â”œâ”€â”€ asl_main.py              # Main control script (250 lines)
â”‚   â”œâ”€â”€ Voice Recognition    # Google Speech API integration
â”‚   â”œâ”€â”€ LLM Interface        # Local LLM API calls
â”‚   â”œâ”€â”€ ASL Pose Library     # A-Z gesture definitions
â”‚   â”œâ”€â”€ Closed-Loop Control  # Joint position feedback
â”‚   â””â”€â”€ PyBullet Simulation  # Physics engine
â”‚
â”œâ”€â”€ my_shadow_hand.urdf      # Robot model definition
â”‚   â”œâ”€â”€ 20 movable joints    # Fingers + wrist
â”‚   â””â”€â”€ Collision meshes     # For physics
â”‚
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md               # Documentation
```

---

### ğŸ¨ Technical Highlights

1. **Intelligent Error Correction**
   - Uses LLM to fix ASR mistakes contextually
   - Handles homophones: "æ€ä¹ˆå‘¨" â†’ "æ€ä¹ˆèµ°"

2. **Closed-Loop Motion Control**
   ```python
   # Waits until joint reaches target Â±0.15 radians
   while time.time() - start < 2.0:
       curr = p.getJointState(robot_id, joint_id)[0]
       if abs(curr - target) < 0.15:
           break
   ```

3. **ASL Gesture Library**
   - 26 letters + REST pose
   - Finger abbreviations: FF (forefinger), MF (middle), RF (ring), LF (little), TH (thumb)
   - Example A: All fingers bent, thumb slightly abducted

4. **Noise Cancellation**
   ```python
   r.adjust_for_ambient_noise(source, duration=0.8)
   r.pause_threshold = 1.5  # Prevents cutting off speech
   ```

---

### ğŸ“Š System Performance

| Metric | Value |
|--------|-------|
| ASR Latency | ~2-3 seconds (Google API) |
| LLM Inference | ~1-2 seconds (Qwen2.5-1.5B on CPU) |
| Gesture Execution | ~1-2 seconds per letter |
| Joint Precision | Â±0.15 radians |
| Physics Timestep | 240 Hz (PyBullet) |

---

### ğŸ”® Future Improvements

- [ ] Add dynamic ASL gestures (not just finger-spelling)
- [ ] Support offline ASR (Whisper integration)
- [ ] Multi-hand coordination for complex phrases
- [ ] Real robot deployment (UR5 + Leap Hand)
- [ ] Web interface for remote control

---

### ğŸ“„ License

MIT License - Feel free to use for educational/research purposes.

---

### ğŸ™ Acknowledgments

- **Shadow Hand Model**: Based on OpenAI Shadow Hand URDF
- **LLM**: Powered by Qwen2.5 (Alibaba Cloud)
- **Physics Engine**: PyBullet
- **Speech Recognition**: Google Cloud Speech-to-Text

---

<a name="chinese"></a>

## ğŸ“– ä¸­æ–‡ç‰ˆæœ¬

### ğŸ¯ é¡¹ç›®æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½æœºæ¢°æ‰‹æ§åˆ¶ç³»ç»Ÿï¼Œèƒ½å¤Ÿ**å¬æ‡‚ä½ çš„å£°éŸ³**ã€**è‡ªåŠ¨çº æ­£è¯†åˆ«é”™è¯¯**ã€**ç¿»è¯‘æˆè‹±æ–‡**ï¼Œå¹¶æ§åˆ¶ä»¿çœŸShadow Handæ‰§è¡Œç¾å¼æ‰‹è¯­(ASL)å­—æ¯æ‹¼å†™æ‰‹åŠ¿ã€‚

**ğŸ¥ æ¼”ç¤ºè§†é¢‘**: [LLM_robots.mp4](../LLM_robots.mp4)

### âœ¨ æ ¸å¿ƒåŠŸèƒ½

- ğŸ¤ **è¯­éŸ³è¯†åˆ«**: é€šè¿‡Googleè¯­éŸ³APIå®æ—¶è¾“å…¥ä¸­æ–‡
- ğŸ§  **AIæ™ºèƒ½çº é”™**: æœ¬åœ°å¤§æ¨¡å‹è‡ªåŠ¨ä¿®å¤åŒéŸ³é”™åˆ«å­—ï¼ˆå¦‚"æ€ä¹ˆå‘¨"â†’"æ€ä¹ˆèµ°"ï¼‰
- ğŸŒ **ç¿»è¯‘åŠŸèƒ½**: ä¸­æ–‡â†’è‹±æ–‡ç¿»è¯‘å¹¶ç”Ÿæˆå­—æ¯åºåˆ—
- ğŸ¤– **é—­ç¯æ§åˆ¶**: å¹³æ»‘è¿åŠ¨ï¼Œå¸¦å…³èŠ‚ä½ç½®åé¦ˆï¼ˆæœç»é¬¼ç•œåŠ¨ä½œï¼‰
- ğŸ”¤ **å®Œæ•´ASLå­—æ¯è¡¨**: æ”¯æŒA-Zæ‰€æœ‰æ‰‹è¯­å­—æ¯
- ğŸ’» **PyBulletç‰©ç†ä»¿çœŸ**: çœŸå®çš„æœºæ¢°æ‰‹ä»¿çœŸï¼Œå¸¦é‡åŠ›å’Œç¢°æ’

---

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è¯­éŸ³è¾“å…¥   â”‚â”€â”€â”€â”€â”€â”€â”‚   å¤§è¯­è¨€æ¨¡å‹  â”‚â”€â”€â”€â”€â”€â”€â”‚  Shadow Hand â”‚
â”‚  (ä¸­æ–‡)     â”‚ è¯†åˆ«  â”‚  (çº é”™+ç¿»è¯‘)  â”‚ JSON â”‚  (PyBullet)  â”‚
â”‚   éº¦å…‹é£    â”‚      â”‚              â”‚      â”‚   ä»¿çœŸæ‰‹     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                     â”‚  LM Studio  â”‚
                     â”‚  æœ¬åœ°APIæœåŠ¡ â”‚
                     â”‚  ç«¯å£: 1234 â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å·¥ä½œæµç¨‹**:
1. ç”¨æˆ·å¯¹éº¦å…‹é£è¯´ä¸­æ–‡
2. Googleè¯­éŸ³APIè½¬æ–‡å­—ï¼ˆå¯èƒ½æœ‰é”™è¯¯ï¼‰
3. æœ¬åœ°LLMçº é”™å¹¶ç¿»è¯‘æˆè‹±æ–‡
4. ç³»ç»Ÿè½¬æ¢ä¸ºå­—æ¯åºåˆ—: `["H","E","L","L","O"]`
5. Shadow Handä¾æ¬¡æ‰§è¡ŒASLæ‰‹åŠ¿

---

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

| éœ€æ±‚é¡¹ | è§„æ ¼ |
|-------|------|
| **æ“ä½œç³»ç»Ÿ** | Windows 10/11, Linux (Ubuntu 20.04+) |
| **Pythonç‰ˆæœ¬** | 3.10 æˆ–æ›´é«˜ |
| **LLMæœåŠ¡å™¨** | [LM Studio](https://lmstudio.ai/) (æœ¬åœ°æ¨ç†) |
| **ç¡¬ä»¶** | éº¦å…‹é£ï¼ˆå¿…éœ€ï¼‰ã€äº’è”ç½‘è¿æ¥ï¼ˆç”¨äºGoogle ASRï¼‰ |
| **æ˜¾å¡** | å¯é€‰ï¼ˆæå‡æ¸²æŸ“è´¨é‡ï¼‰ |

---

### ğŸš€ å®‰è£…æ­¥éª¤

#### ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡é¡¹ç›®æ–‡ä»¶

ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶åœ¨**åŒä¸€ç›®å½•**ä¸‹:
```
asl_robot_project/
â”œâ”€â”€ asl_main.py              # ä¸»æ§åˆ¶è„šæœ¬
â”œâ”€â”€ my_shadow_hand.urdf      # Shadow Handæœºå™¨äººæ¨¡å‹
â”œâ”€â”€ requirements.txt         # Pythonä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                # æœ¬æ–‡æ¡£
```

#### ç¬¬äºŒæ­¥ï¼šå®‰è£…Pythonä¾èµ–

**Windowsç³»ç»Ÿ:**
```bash
pip install -r requirements.txt

# å¦‚æœpyaudioå®‰è£…å¤±è´¥ï¼Œä½¿ç”¨:
pip install pipwin
pipwin install pyaudio
```

**Linuxç³»ç»Ÿ (Ubuntu):**
```bash
# å®‰è£…ç³»ç»Ÿçº§éŸ³é¢‘åº“
sudo apt-get update
sudo apt-get install python3-pyaudio portaudio19-dev

# å®‰è£…PythonåŒ…
pip install -r requirements.txt
```

#### ç¬¬ä¸‰æ­¥ï¼šé…ç½®LM Studioï¼ˆå¤§æ¨¡å‹æœåŠ¡å™¨ï¼‰

1. ä¸‹è½½å¹¶å®‰è£… [LM Studio](https://lmstudio.ai/)
2. æ‰“å¼€LM Studioå¹¶ä¸‹è½½æ¨¡å‹ï¼š
   - **æ¨è**: `Qwen2.5-1.5B-Instruct`ï¼ˆé€Ÿåº¦å¿«ï¼‰æˆ– `Qwen2.5-7B-Instruct`ï¼ˆæ›´å‡†ç¡®ï¼‰
3. ç‚¹å‡»å·¦ä¾§æ çš„ **Local Server**ï¼ˆåŒå‘ç®­å¤´å›¾æ ‡ï¼‰
4. ç‚¹å‡»é¡¶éƒ¨ç»¿è‰² **Start Server** æŒ‰é’®
5. ç¡®è®¤æ§åˆ¶å°æ˜¾ç¤º: `Server running at http://localhost:1234`

---

### ğŸ® ä½¿ç”¨æ–¹æ³•

#### å¯åŠ¨ç³»ç»Ÿ

```bash
python asl_main.py
```

**é¢„æœŸè¾“å‡º:**
```
æ­£åœ¨å¯åŠ¨ PyBullet...
=== Shadow Hand æ™ºèƒ½æ§åˆ¶ç³»ç»Ÿ ===
æ“ä½œæŒ‡å—: æŒ‰ 'v' é”®è¯´è¯ï¼ŒæŒ‰ 'q' é€€å‡º

è¾“å…¥æŒ‡ä»¤ (v=è¯­éŸ³, q=é€€å‡º):
```

#### æ“ä½œæ¨¡å¼

**æ¨¡å¼Aï¼šè¯­éŸ³æ§åˆ¶ï¼ˆæ¨è âœ¨ï¼‰**

1. è¾“å…¥ `v` å¹¶æŒ‰å›è½¦
2. ç­‰å¾…æç¤º: `ğŸ¤ æ­£åœ¨è°ƒæ•´ç¯å¢ƒå™ªéŸ³...`ï¼ˆä¿æŒå®‰é™1ç§’ï¼‰
3. çœ‹åˆ° `ğŸ”´ è¯·è¯´è¯! (Listening...)`æ—¶ï¼Œå¯¹ç€éº¦å…‹é£è¯´ä¸­æ–‡
   - ç¤ºä¾‹: *"ä½ å¥½æˆ‘æƒ³å»å­¦æ ¡"*
4. ç³»ç»Ÿå°†ï¼š
   - è¯†åˆ«è¯­éŸ³ â†’ çº æ­£é”™è¯¯ â†’ ç¿»è¯‘ â†’ æ‰§è¡ŒASLæ‰‹åŠ¿

**ç¤ºä¾‹è¾“å‡º:**
```
ğŸ‘‚ å¬åˆ°: ã€ ä½ å¥½æ€ä¹ˆå‘¨ ã€‘
ğŸ§  å‘é€ç»™å¤§è„‘çº é”™: ä½ å¥½æ€ä¹ˆå‘¨ ...
âœ¨ æ™ºèƒ½çº é”™: ä½ å¥½æ€ä¹ˆèµ°
ğŸ“– ç¿»è¯‘ç»“æœ: HELLO HOW TO GO
å‡†å¤‡æ‰§è¡Œåºåˆ—: ['H', 'E', 'L', 'L', 'O', ' ', 'H', 'O', 'W', ...]
>>> åŠ¨ä½œ: H
>>> åŠ¨ä½œ: E
...
```

**æ¨¡å¼Bï¼šæ–‡å­—è¾“å…¥ï¼ˆè°ƒè¯•ç”¨ï¼‰**

1. ç›´æ¥åœ¨æç¤ºç¬¦ä¸‹è¾“å…¥ä¸­æ–‡æˆ–è‹±æ–‡
   - ç¤ºä¾‹: `Hello World` æˆ– `ä½ å¥½`
2. æŒ‰å›è½¦æ‰§è¡Œæ‰‹åŠ¿

**é€€å‡ºç¨‹åº:**
- è¾“å…¥ `q` å¹¶æŒ‰å›è½¦

---

### ğŸ§ª æµ‹è¯•åœºæ™¯

ç”¨æŒ‘æˆ˜æ€§è¾“å…¥æµ‹è¯•ç³»ç»Ÿæ™ºèƒ½ç¨‹åº¦ï¼š

#### æµ‹è¯•1ï¼šåŒéŸ³å­—çº æ­£
- **è¯­éŸ³è¾“å…¥**: "æˆ‘æƒ³å»**ç¢è§‰**"ï¼ˆæ•…æ„é”™è¯¯ï¼‰
- **ç³»ç»Ÿè¾“å‡º**:
  ```
  âœ¨ æ™ºèƒ½çº é”™: æˆ‘æƒ³å»ç¡è§‰
  ğŸ“– ç¿»è¯‘: I WANT TO SLEEP
  ```
- **åŠ¨ä½œ**: æ‹¼å†™ `S-L-E-E-P`

#### æµ‹è¯•2ï¼šé•¿å¥ç¿»è¯‘
- **è¯­éŸ³è¾“å…¥**: "æœºå™¨äººæŠ€æœ¯éå¸¸æœ‰è¶£"
- **ç³»ç»Ÿè¾“å‡º**:
  ```
  ğŸ“– ç¿»è¯‘: ROBOTICS IS VERY INTERESTING
  ```
- **åŠ¨ä½œ**: æ‹¼å†™å®Œæ•´å¥å­

---

### ğŸ”§ é…ç½®è¯´æ˜

#### APIç«¯ç‚¹ï¼ˆ`asl_main.py`ç¬¬10è¡Œï¼‰
```python
API_URL = "http://localhost:1234/v1/chat/completions"
```
- é»˜è®¤ç«¯å£æ˜¯ `1234`ï¼ˆLM Studioé»˜è®¤å€¼ï¼‰
- å¦‚ä½¿ç”¨å…¶ä»–LLMæœåŠ¡å™¨è¯·ä¿®æ”¹

#### å›¾å½¢æ¨¡å¼ï¼ˆ`asl_main.py`ç¬¬33è¡Œï¼‰
```python
# å½“å‰ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰:
p.connect(p.GUI, options="--opengl2")

# é«˜æ€§èƒ½æ¨¡å¼ï¼ˆéœ€è¦å¥½æ˜¾å¡ï¼‰:
p.connect(p.GUI)
```
- å¦‚æœæœ‰NVIDIAæ˜¾å¡ï¼Œå¯åˆ é™¤ `options="--opengl2"` è·å¾—æ›´å¥½å›¾å½¢
- å¦‚æœå´©æºƒè¯·æ”¹å›åŸæ ·

---

### ğŸ› ï¸ å¸¸è§é—®é¢˜

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|---------|
| `ModuleNotFoundError: speech_recognition` | è¿è¡Œ: `pip install SpeechRecognition` |
| è¯­éŸ³è¯†åˆ«è¶…æ—¶ | 1. æ£€æŸ¥äº’è”ç½‘è¿æ¥<br>2. ç¡®ä¿éº¦å…‹é£æœªé™éŸ³<br>3. è¯´è¯å£°éŸ³å¤§ä¸€ç‚¹ã€æ…¢ä¸€ç‚¹ |
| LLM `Connection Error` | ç¡®è®¤LM StudioæœåŠ¡å™¨è¿è¡Œåœ¨1234ç«¯å£ |
| æœºæ¢°æ‰‹åŠ¨ä½œå¤ªæ…¢ | **æ­£å¸¸ç°è±¡** - é—­ç¯æ§åˆ¶ç¡®ä¿å¹³æ»‘è¿åŠ¨ |
| URDFåŠ è½½é”™è¯¯ | ç¡®è®¤ `my_shadow_hand.urdf` ä¸è„šæœ¬åœ¨åŒä¸€ç›®å½• |
| PyBulletå´©æºƒ | åœ¨ `p.connect()` è¡Œæ·»åŠ  `options="--opengl2"` |

---

### ğŸ“‚ é¡¹ç›®ç»“æ„

```
asl_robot_project/
â”œâ”€â”€ asl_main.py              # ä¸»æ§åˆ¶è„šæœ¬ï¼ˆ250è¡Œï¼‰
â”‚   â”œâ”€â”€ è¯­éŸ³è¯†åˆ«æ¨¡å—          # Google Speech APIé›†æˆ
â”‚   â”œâ”€â”€ LLMæ¥å£             # æœ¬åœ°å¤§æ¨¡å‹APIè°ƒç”¨
â”‚   â”œâ”€â”€ ASLå§¿æ€åº“            # A-Zæ‰‹åŠ¿å®šä¹‰
â”‚   â”œâ”€â”€ é—­ç¯æ§åˆ¶            # å…³èŠ‚ä½ç½®åé¦ˆ
â”‚   â””â”€â”€ PyBulletä»¿çœŸ        # ç‰©ç†å¼•æ“
â”‚
â”œâ”€â”€ my_shadow_hand.urdf      # æœºå™¨äººæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ 20ä¸ªå¯åŠ¨å…³èŠ‚         # æ‰‹æŒ‡+æ‰‹è…•
â”‚   â””â”€â”€ ç¢°æ’ç½‘æ ¼            # ç”¨äºç‰©ç†æ¨¡æ‹Ÿ
â”‚
â”œâ”€â”€ requirements.txt         # ä¾èµ–é¡¹
â””â”€â”€ README.md               # æ–‡æ¡£
```

---

### ğŸ¨ æŠ€æœ¯äº®ç‚¹

1. **æ™ºèƒ½çº é”™ç®—æ³•**
   - ä½¿ç”¨LLMæ ¹æ®ä¸Šä¸‹æ–‡ä¿®å¤ASRé”™è¯¯
   - å¤„ç†åŒéŸ³å­—: "æ€ä¹ˆå‘¨" â†’ "æ€ä¹ˆèµ°"

2. **é—­ç¯è¿åŠ¨æ§åˆ¶**
   ```python
   # ç­‰å¾…å…³èŠ‚åˆ°è¾¾ç›®æ ‡ä½ç½®Â±0.15å¼§åº¦
   while time.time() - start < 2.0:
       curr = p.getJointState(robot_id, joint_id)[0]
       if abs(curr - target) < 0.15:
           break
   ```

3. **ASLæ‰‹åŠ¿åº“**
   - 26ä¸ªå­—æ¯ + RESTå¤ä½å§¿æ€
   - æ‰‹æŒ‡ç¼©å†™: FF(é£ŸæŒ‡), MF(ä¸­æŒ‡), RF(æ— åæŒ‡), LF(å°æŒ‡), TH(æ‹‡æŒ‡)
   - ç¤ºä¾‹A: æ‰€æœ‰æ‰‹æŒ‡å¼¯æ›²ï¼Œæ‹‡æŒ‡ç¨å¤–å±•

4. **å™ªéŸ³æ¶ˆé™¤**
   ```python
   r.adjust_for_ambient_noise(source, duration=0.8)
   r.pause_threshold = 1.5  # é˜²æ­¢è¯­éŸ³è¢«æˆªæ–­
   ```

---

### ğŸ“Š ç³»ç»Ÿæ€§èƒ½

| æŒ‡æ ‡ | æ•°å€¼ |
|-----|------|
| ASRå»¶è¿Ÿ | ~2-3ç§’ï¼ˆGoogle APIï¼‰ |
| LLMæ¨ç† | ~1-2ç§’ï¼ˆQwen2.5-1.5B CPUï¼‰ |
| æ‰‹åŠ¿æ‰§è¡Œ | ~1-2ç§’/å­—æ¯ |
| å…³èŠ‚ç²¾åº¦ | Â±0.15å¼§åº¦ |
| ç‰©ç†æ—¶é—´æ­¥ | 240 Hzï¼ˆPyBulletï¼‰ |

---

### ğŸ”® æœªæ¥æ”¹è¿›

- [ ] æ·»åŠ åŠ¨æ€ASLæ‰‹åŠ¿ï¼ˆä¸ä»…æ˜¯å­—æ¯æ‹¼å†™ï¼‰
- [ ] æ”¯æŒç¦»çº¿ASRï¼ˆWhisperé›†æˆï¼‰
- [ ] åŒæ‰‹åè°ƒç”¨äºå¤æ‚çŸ­è¯­
- [ ] çœŸå®æœºå™¨äººéƒ¨ç½²ï¼ˆUR5 + Leap Handï¼‰
- [ ] Webç•Œé¢è¿œç¨‹æ§åˆ¶

---

### ğŸ“„ è®¸å¯è¯

MIT License - æ¬¢è¿ç”¨äºæ•™è‚²/ç ”ç©¶ç›®çš„

---


